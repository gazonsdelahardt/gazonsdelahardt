import random
import requests
import json
import os
import csv
import threading
import time
from datetime import datetime, timedelta
from dotenv import load_dotenv
from flask import Flask, request, jsonify
from openai import OpenAI
from collections import defaultdict
from collections import deque

processed_message_ids = set()
processed_order = deque(maxlen=2000)

# ParamÃ¨tre dÃ©lai avant relance
SILENCE_AFTER = timedelta(minutes=5)   # prod = 10 min ; pour test tu peux mettre 1

# =====================
# Load Environment Vars
# =====================
load_dotenv()

# MÃ©moire lÃ©gÃ¨re par contact (in-memory)
last_user_at = defaultdict(lambda: None)    # derniÃ¨re heure dâ€™un message client
last_bot_at = defaultdict(lambda: None)     # derniÃ¨re heure dâ€™un message IA
followup_sent = defaultdict(lambda: False)  # relance dÃ©jÃ  envoyÃ©e ?

from pathlib import Path

HISTORY_FILE = Path("chat_history.csv")
HISTORY_FILE.touch(exist_ok=True)

def append_history(wa_id: str, role: str, content: str) -> None:
    """Ajoute une ligne d'historique (wa_id, role=user/assistant, content, timestamp)."""
    with HISTORY_FILE.open("a", newline="") as f:
        w = csv.writer(f)
        w.writerow([wa_id, role, content, datetime.utcnow().isoformat()])

def read_history(wa_id: str, limit: int = 20):
    """Retourne les 'limit' derniers messages (role, content) pour ce wa_id."""
    rows = []
    if not HISTORY_FILE.exists():
        return rows
    with HISTORY_FILE.open("r", newline="") as f:
        r = csv.reader(f)
        for row in r:
            if len(row) < 4:
                continue
            if row[0] == wa_id:
                rows.append({"role": row[1], "content": row[2]})
    return rows[-limit:]



VERIFY_TOKEN = os.getenv("VERIFY_TOKEN")           # Meta Verify Token
WHATSAPP_TOKEN = os.getenv("WHATSAPP_TOKEN")       # Permanent WhatsApp token
PHONE_NUMBER_ID = os.getenv("PHONE_NUMBER_ID")     # WhatsApp Phone Number ID

# --- OpenAI client & modÃ¨le ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
if not OPENAI_API_KEY:
    raise RuntimeError("OPENAI_API_KEY manquant dans .env")

client = OpenAI(api_key=OPENAI_API_KEY)

# Choisir le modÃ¨le via .env (fallback sur un modÃ¨le rÃ©el)
MODEL_NAME = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

CHAT_CSV = "chat_history.csv"
CUSTOMER_FILE = "customers.csv"

# =====================
# Flask + OpenAI
# =====================
from flask import Flask
app = Flask(__name__)

from openai import OpenAI
client = OpenAI(api_key=OPENAI_API_KEY)


# =====================
# Memory (per user chat)
# =====================
conversations = defaultdict(list)  # { wa_id: [messages] }
customers = set()  # unique customer IDs for promotions


# =====================
# Save Chat History (CSV)
# =====================
def save_chat_to_csv(wa_id, role, content):
    """Append a new chat message to CSV file"""
    with open(CHAT_CSV, mode="a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow([datetime.now().isoformat(), wa_id, role, content])


# Ensure CSV has headers
if not os.path.exists(CHAT_CSV):
    with open(CHAT_CSV, mode="w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["timestamp", "wa_id", "role", "content"])


# =====================
# Follow-up Worker (relance aprÃ¨s silence)
# =====================

# =====================
# Follow-up Worker (relance aprÃ¨s silence)
# =====================

def followup_worker():
    """
    Envoie une relance si l'utilisateur n'a pas rÃ©pondu aprÃ¨s SILENCE_AFTER,
    Ã  condition que le bot ait bien rÃ©pondu aprÃ¨s le dernier message utilisateur,
    et que la conversation soit < 24h.
    """
    CHECK_EVERY = 20  # frÃ©quence de vÃ©rification (secondes)

    # Log de configuration au dÃ©marrage du worker
    print(f"[config] SILENCE_AFTER={SILENCE_AFTER}, CHECK_EVERY={CHECK_EVERY}", flush=True)

    while True:
        try:
            now = datetime.utcnow()
            for wa_id, last_user in list(last_user_at.items()):
                if not last_user:
                    print(f"[followup] skip {wa_id}: no last_user", flush=True)
                    continue

                if followup_sent.get(wa_id, False):
                    print(f"[followup] skip {wa_id}: already sent", flush=True)
                    continue

                last_bot = last_bot_at.get(wa_id)

                # Log des timestamps connus pour ce user
                print(
                    f"[followup] {wa_id}: last_user={last_user.isoformat()}, "
                    f"last_bot={(last_bot.isoformat() if last_bot else None)}",
                    flush=True
                )

                # Le bot doit avoir rÃ©pondu aprÃ¨s le dernier message user
                if not last_bot or last_bot <= last_user:
                    print(
                        f"[followup] skip {wa_id}: bot_not_after_user "
                        f"(last_bot={last_bot}, last_user={last_user})",
                        flush=True
                    )
                    continue

                delta = now - last_user
                # Log du delta et du seuil
                print(
                    f"[followup] {wa_id}: delta={delta}, threshold={SILENCE_AFTER}",
                    flush=True
                )

                if not (SILENCE_AFTER <= delta <= timedelta(hours=24)):
                    print(
                        f"[followup] wait {wa_id}: delta={delta}, "
                        f"window=({SILENCE_AFTER}, 24h)",
                        flush=True
                    )
                    continue

                print(f"[followup] SEND nudge to {wa_id} (delta={delta})", flush=True)
                try:
                    nudge = random.choice([
                        "Souhaitez-vous que je vous aide Ã  estimer la surface ou la livraison ?",
                        "Je peux vous guider entre Elite et Water Saver si vous hÃ©sitez.",
                        "Besoin dâ€™un rÃ©cap rapide sur lâ€™entretien (arrosage, tonte, engrais) ?",
                        "Je reste dispo si vous avez une question ðŸ™‚"
                    ])
                    send_whatsapp_message(wa_id, nudge)
                    followup_sent[wa_id] = True
                    last_bot_at[wa_id] = now
                    print(f"[followup] sent to {wa_id}", flush=True)
                except Exception as e:
                    print("followup send error:", e, flush=True)

            # RÃ©sumÃ© dâ€™itÃ©ration
            print(
                f"[followup] loop: users={len(last_user_at)}, "
                f"sent_flags={sum(1 for v in followup_sent.values() if v)}",
                flush=True
            )

        except Exception as e:
            print("followup worker error:", e, flush=True)

        # Petit jitter pour Ã©viter les envois trop synchronisÃ©s
        time.sleep(CHECK_EVERY + random.uniform(0, 2))


# =====================
# Customer Management
# =====================
def load_customers():
    """Load customers from file"""
    if os.path.exists(CUSTOMER_FILE):
        with open(CUSTOMER_FILE, "r", encoding="utf-8") as f:
            for line in f:
                number = line.strip()
                if number:
                    customers.add(number)

def save_customer(wa_id):
    """Add new customer to file if not already saved"""
    if wa_id not in customers:
        customers.add(wa_id)
        with open(CUSTOMER_FILE, "a", encoding="utf-8") as f:
            f.write(f"{wa_id}\n")

# Load customers on startup
load_customers()


# =====================
# WhatsApp Messaging
# =====================
def send_whatsapp_message(wa_id, text):
    """Send a WhatsApp message. Fallback to template if >24h window closed."""
    url = f"https://graph.facebook.com/v23.0/{PHONE_NUMBER_ID}/messages"
    headers = {
        "Authorization": f"Bearer {WHATSAPP_TOKEN}",
        "Content-Type": "application/json"
    }

    # Try free-form message first
    payload = {
        "messaging_product": "whatsapp",
        "to": wa_id,
        "type": "text",
        "text": {"body": text}
    }

    response = requests.post(url, headers=headers, data=json.dumps(payload))
    result = response.json()
    print("WA send status:", response.status_code, response.text, flush=True)

    # Amorcer un suivi mÃªme en outbound-first
    if wa_id not in last_user_at or last_user_at[wa_id] is None:
        last_user_at[wa_id] = datetime.utcnow()
        followup_sent[wa_id] = False
        print(f"[followup] outbound-first init for {wa_id} at {last_user_at[wa_id].isoformat()}", flush=True)

    # âœ… If 24h window expired, send template instead




# --- Flask app ---
app = Flask(__name__)

def send_promo_template(wa_id):
    """Always send the weekly_promo template for promotions"""
    url = f"https://graph.facebook.com/v23.0/{PHONE_NUMBER_ID}/messages"
    headers = {
        "Authorization": f"Bearer {WHATSAPP_TOKEN}",
        "Content-Type": "application/json"
    }

    template_payload = {
        "messaging_product": "whatsapp",
        "to": wa_id,
        "type": "template",
        "template": {
            "name": "hello_world",   # ðŸ‘ˆ your approved promo template
            "language": {"code": "en_US"}  # ðŸ‘ˆ must match template language
        }
    }

    response = requests.post(url, headers=headers, data=json.dumps(template_payload))
    result = response.json()
    print(f"ðŸ“¤ Promo API response for {wa_id}:", result)
    return result


# =====================
# Promotion Scheduler
# =====================
last_promo_date = None

def promotion_worker():
    global last_promo_date
    while True:
        now = datetime.now()
        days_ahead = (5 - now.weekday()) % 7   # every Friday
        next_run = now + timedelta(days=days_ahead)
        next_run = next_run.replace(hour=20, minute=59, second=0, microsecond=0)

        if next_run <= now:
            next_run += timedelta(days=7)

        wait_time = (next_run - now).total_seconds()
        time.sleep(wait_time)

        if last_promo_date == next_run.date():
            continue  # already sent today

        print("ðŸš€ Sending weekly promo template...")
        for wa_id in customers:
            send_promo_template(wa_id)

        last_promo_date = next_run.date()

# --- DÃ©marre le worker une seule fois (compatible Render/Gunicorn) ---
try:
    _FOLLOWUP_STARTED
except NameError:
    _FOLLOWUP_STARTED = True


# =====================
# System prompt (role)
# =====================

GAZONS_PROMPT = """
Tu es le conseiller officiel de lâ€™entreprise Â« Gazons de la Hardt Â», producteur et distributeur de gazon en rouleau.
Entreprise familiale bientÃ´t cinquantenaire (â‰ˆ50 ans), nous produisons du gazon en rouleau depuis 10 ans.

OBJECTIF
- RÃ©ponds en franÃ§ais, ton professionnel, chaleureux, pÃ©dagogique (toujours vouvoiement).
- Aide le client Ã  dÃ©finir prÃ©cisÃ©ment son besoin : surface (mÂ²), choix du mÃ©lange, besoins en engrais, prÃ©paration du sol.
- Mets en avant le gazon en rouleau : densitÃ© immÃ©diate, gain de temps vs semis, utilisable tout de suite.
- Donne des conseils techniques simples (prÃ©paration du sol, nivelage, arrosage, entretien).
- Une fois le besoin dÃ©fini (surface + mÃ©lange + engrais), invite Ã  contacter lâ€™Ã©quipe pour devis/commande.
- Une fois que la demande du client est claire, indique lui les coordoonÃ©es de l'entreprise pour nous joinre en nous communiquant les articles dont il a besoin

NOTRE OFFRE (Ã  citer selon lâ€™intÃ©rÃªt)
1) PrÃ©paration du sol :
   - Â« MÃ©lange Terre Compost Â» â€“ densitÃ© 1 t = 1 mÂ³, livrable en vrac, big bag ou sac.
   - Conseils techniques : dÃ©compacter, niveler, mÃ©langer la Terre Compost avec la terre existante sur 5â€“10 cm pour crÃ©er un support homogÃ¨ne (pose des rouleaux / semis).
   - Le MÃ©lange Terre Compost nâ€™est pas obligatoire, mais il amÃ©liore nettement la reprise et lâ€™enracinement plus profond.
   - Terre pure Ã©galement disponible si besoin de rehausser le terrain.
2) Gazon en rouleau â€“ proposer systÃ©matiquement deux alternatives :
   â€¢ Water Saver : 80% fÃ©tuque Ã©levÃ©e, 15% pÃ¢turin des prÃ©s, 5% ray-grass anglais (rÃ©sistance sÃ©cheresse).
   â€¢ MÃ©lange qualitatif : 50% ray-grass anglais, 50% pÃ¢turin des prÃ©s (aspect plus haut de gamme, meilleure tenue au piÃ©tinement).
3) Engrais et complÃ©ments :
   - Engrais racinaire (sous le gazon) et engrais foliaire (entretien), semences de gazon, Terre / MÃ©lange Terre Compost.
   - Tout est vendu au poids (kg) ou Ã  la tonne. Possibles petits seaux ou vrac si le client vient Ã©quipÃ©.
   - Produits complÃ©mentaires (si intÃ©rÃªt manifeste) : cailloux dÃ©coratifs, bois sec ONF.
4) Livraison : via transporteurs. Mentionner le principe et lâ€™accÃ¨s camion si on te le demande ; ne pas promettre de date.

DIAGNOSTIC Ã€ POSER (si infos manquantes)
- Surface (mÂ²) OU dimensions des zones (rectangles, cercles) pour calculer la surface.
- Souhaitez-vous une marge de dÃ©coupe ? (recommandation : +3 Ã  +5 % selon formes/obstacles).
- Exposition (soleil/ombre), possibilitÃ© dâ€™arrosage.
- Usage & contrainte : famille, sportif, fort piÃ©tinement, Ã©conomie dâ€™eau.
- Calendrier souhaitÃ© et accÃ¨s camion pour la livraison.

CALCULS Ã€ PRODUIRE (dÃ¨s que la surface est connue)
- Surface finale = (somme des zones) Ã— (1 + marge de dÃ©coupe recommandÃ©e 3â€“5 %).
- Engrais racinaire (sous le gazon) : 50 g/mÂ² â†’ QuantitÃ© = 0,05 kg Ã— surface finale (arrondir au 0,1 kg supÃ©rieur).
- Engrais foliaire (entretien) : 40 g/mÂ² par application, 3Ã—/an (mars, juin, septembre)
  â†’ Par application = 0,04 kg Ã— surface finale ; Annuel = 0,12 kg Ã— surface finale (arrondir au 0,1 kg supÃ©rieur).
- PrÃ©senter clairement : surface retenue, kg dâ€™engrais racinaire, kg dâ€™engrais foliaire par application et par an.

RÃˆGLES DE RECOMMANDATION
- SÃ©cheresse / arrosage limitÃ© / Ã©conomie dâ€™eau â†’ Water Saver.
- PrioritÃ© esthÃ©tique premium / piÃ©tinement soutenu â†’ MÃ©lange qualitatif.
- Si le client insiste pour du semis â†’ proposer nos graines (en rappelant les bÃ©nÃ©fices du rouleau) + engrais.
- Toujours recommander en amont le Â« MÃ©lange Terre Compost Â» pour favoriser la reprise.

COORDONNÃ‰ES POUR DEVIS/COMMANDE
- Mail : contact@gdlh.fr
- TÃ©lÃ©phone : +33 6 71 22 75 68 (alternatif : 06 38 14 25 19)
- Site : www.gdlh.fr
âš ï¸ Important : la chatbox ne peut pas transmettre la demande directement Ã  nos Ã©quipes. Câ€™est au client de nous contacter par mail ou tÃ©lÃ©phone pour finaliser un devis ou une commande.

STYLE DE RÃ‰PONSE
- Phrases courtes, positives, naturelles. Varier les formulations.
- Accueillir/valider, rÃ©pondre clairement, ajouter un conseil, puis poser une question ouverte.
- Exemples : Â« Parfait ! Â», Â« Bonne nouvelle ! Â», Â« Je comprends tout Ã  fait. Â»

LIMITES (strict)
- Ne jamais donner de prix.
- Ne pas sâ€™engager sur des dates de livraison.
- Ne pas parler de dÃ©sherbants / produits chimiques.
- Ne jamais dire que tu es une IA.
- Toujours rappeler quâ€™il faut contacter lâ€™entreprise (mail ou tÃ©lÃ©phone) pour toute commande ou devis.

OBJECTIF FINAL
Donner au client le sentiment dâ€™Ã©changer avec un conseiller dÃ©diÃ©, fiable et efficace, qui dÃ©finit prÃ©cisÃ©ment son besoin, calcule les quantitÃ©s dâ€™engrais, conseille la prÃ©paration du sol et oriente vers le gazon en rouleau.
"""


# =====================
# Webhook Endpoint
# =====================

# --- RÃ©ception messages (POST) ---
@app.route("/webhook", methods=["POST"])
def webhook():
    try:
        data = request.get_json(force=True, silent=True) or {}
        print("Incoming webhook:", json.dumps(data, indent=2), flush=True)

        entry = data.get("entry", [{}])[0]
        changes = entry.get("changes", [{}])[0]
        value = changes.get("value", {})

        # Ignore accusÃ©s de rÃ©ception/lecture
        if "statuses" in value:
            return jsonify({"status": "ignored_status"}), 200

        # Traite seulement les messages entrants
        if "messages" in value:
            msg = value["messages"][0]
            msg_id = msg.get("id") or ""

            # --- DÃ©duplication: ignore si dÃ©jÃ  traitÃ© ---
            if msg_id in processed_message_ids:
                return jsonify({"status": "duplicate_ignored"}), 200
            processed_message_ids.add(msg_id)
            processed_order.append(msg_id)
            if len(processed_message_ids) > 5000:
                while len(processed_message_ids) > 4000 and processed_order:
                    processed_message_ids.discard(processed_order.popleft())

            wa_id = msg.get("from")
            msg_type = msg.get("type")
            user_text = ""

            if msg_type == "text":
                user_text = msg.get("text", {}).get("body", "")
            elif msg_type == "interactive":
                interactive = msg.get("interactive", {})
                # boutons / listes
                user_text = interactive.get("button_reply", {}).get("title") or \
                            interactive.get("list_reply", {}).get("title") or ""
            else:
                user_text = "(message non-textuel reÃ§u)"

            last_user_at[wa_id] = datetime.utcnow()
            followup_sent[wa_id] = False
            print(
                f"[followup] GOT user msg from {wa_id} at {last_user_at[wa_id].isoformat()} : {user_text}",
                flush=True
            )

            # --- GÃ©nÃ¨re une rÃ©ponse (OpenAI si possible, sinon fallback simple) ---
            reply_text = None
            try:
                if OPENAI_API_KEY:
                    # 1) mÃ©moriser le message utilisateur
                    if user_text:
                        append_history(wa_id, "user", user_text)

                    # 2) recharger l'historique (20 derniers Ã©changes)
                    past = read_history(wa_id, limit=20)

                    # 3) prompt systÃ¨me complet
                    system_prompt = GAZONS_PROMPT

                    # 4) Construire le contexte avec mÃ©moire
                    messages = [{"role": "system", "content": system_prompt}]
                    messages.extend(past)
                    messages.append({"role": "user", "content": user_text or "Bonjour"})

                    # 5) Appel OpenAI
                    chat = client.chat.completions.create(
                        model=MODEL_NAME,          # <-- utilise bien model6 ici
                        temperature=0.7,
                        max_tokens=350,
                        messages=messages
                    )
                    reply_text = (chat.choices[0].message.content or "").strip()

                    # 6) MÃ©moriser la rÃ©ponse IA
                    if reply_text:
                        append_history(wa_id, "assistant", reply_text)

                    # 7) Relance finale optionnelle (50%)
                    def wants_question(user_txt, ai_txt):
                        if "?" in (ai_txt or ""):
                            return False
                        keywords = ["prix", "tarif", "devis", "livraison", "planning", "disponible", "stock"]
                        if any(k in (ai_txt or "").lower() for k in keywords):
                            return False
                        return random.random() < 0.5

                    if wants_question(user_text or "", reply_text or ""):
                        closing_question = random.choice([
                            "Vous prÃ©fÃ©rez viser lâ€™esthÃ©tique, lâ€™Ã©conomie dâ€™eau, ou la simplicitÃ© dâ€™entretien ?",
                            "Souhaitez-vous quâ€™on estime la surface et la livraison ?",
                            "Vous avez dÃ©jÃ  une date en tÃªte pour la pose ?",
                            "Je vous dÃ©taille lâ€™entretien (arrosage, tonte, engrais) ?"
                        ])
                        if not reply_text.strip().endswith(("?", "ï¼Ÿ")):
                            reply_text = reply_text.rstrip(".!â€¦ ") + " " + closing_question

            except Exception as e:
                print("OpenAI error:", e, flush=True)

            if not reply_text:
                # Fallback sans question systÃ©matique (âš ï¸ ta chaÃ®ne Ã©tait cassÃ©e, je lâ€™ai rÃ©parÃ©e)
                reply_text = (
                    "Merci pour votre message ðŸ‘‹ Le gazon en rouleau offre une densitÃ© immÃ©diate et fait gagner du temps "
                    "par rapport au semis, tout en demandant un entretien raisonnable (arrosage, tonte, 3 apports dâ€™engrais/an)."
                )

            # --- Envoi WhatsApp + sortie webhook ---
            try:
                send_whatsapp_message(wa_id, reply_text)
                last_bot_at[wa_id] = datetime.utcnow()
                print(f"[followup] BOT replied to {wa_id} at {last_bot_at[wa_id].isoformat()}", flush=True)
            except Exception as e:
                print("send_whatsapp_message error:", e, flush=True)
            return jsonify({"status": "ok"}), 200

        # Rien dâ€™utile
        return jsonify({"status": "no_message"}), 200

    except Exception as e:
        print("Webhook error:", e, flush=True)
        return jsonify({"status": "error", "detail": str(e)}), 500


# --- MAIN (unique) ---
if __name__ == "__main__":
    import os
    import threading
    import time

    print("ðŸš€ Lancement de lâ€™assistant Gazons de la Hardt (model6)")

    # DÃ©marrer les workers en arriÃ¨re-plan (protÃ©gÃ©s)
    try:
        threading.Thread(target=followup_worker, daemon=True).start()
        print(">>> followup_worker STARTED", flush=True)
    except Exception as e:
        print("followup_worker start error:", e, flush=True)

    try:
        threading.Thread(target=promotion_worker, daemon=True).start()
        print(">>> promotion_worker STARTED", flush=True)
    except Exception as e:
        print("promotion_worker start error:", e, flush=True)

    # Lancer le serveur Flask (bloquant) â€” pas de reloader en prod
    port = int(os.environ.get("PORT", 5050))
    app.run(host="0.0.0.0", port=port, debug=False, use_reloader=False)
